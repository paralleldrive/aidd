# Test: Code Review Command Usage

**Persona**: Alex Chen â€” Senior Software Engineer conducting code reviews

## Pre-test

- Start screen recording
- Clear state (cookies, cache, cart)
- Prepare credentials if needed
- Open VS Code workspace with the aidd project
- Ensure there are staged or uncommitted changes to review

## Instructions

Read each step out loud before attempting it. Think aloud as you work - this helps reviewers follow along.

## Steps

### Step 1

- **Goal**: Set up environment to review recent changes
- **Do**: Open the workspace in VS Code with uncommitted or staged changes ready for review
- **Think aloud**: What do you see? Any friction?
- **Success**: Workspace is loaded, changes are visible in source control panel, and AI assistant is accessible

### Step 2

- **Goal**: Start a comprehensive code review using the AI assistant
- **Do**: Open Copilot Chat and type `/review` command
- **Think aloud**: How responsive is the command? Is it clear what's happening?
- **Success**: AI assistant acknowledges the command and begins the review process, displaying progress indicators

### Step 3 (Checkpoint)

- **Goal**: Ensure AI reads relevant project rules, standards, and guidelines
- **Do**: Observe AI reading please.mdc, review.mdc, and relevant stack/language guidelines
- **Think aloud**: Can you tell what the AI is doing? Is there enough feedback?
- **Success**: AI displays messages indicating it's reading project constraints and coding standards

### Step 4

- **Goal**: Get feedback on code organization and architecture
- **Do**: Read the AI's analysis of code structure, comparing against task plans
- **Think aloud**: Is the feedback specific enough? Are the file references helpful?
- **Success**: AI provides specific feedback on code organization with file path references

### Step 5 (Checkpoint)

- **Goal**: Validate adherence to project coding standards
- **Do**: Review the AI's feedback on coding standards violations
- **Think aloud**: Are the line-specific references accurate? Are suggestions actionable?
- **Success**: AI identifies violations with line-specific references and improvement suggestions

### Step 6

- **Goal**: Assess test quality and completeness
- **Do**: Examine AI's test coverage analysis
- **Think aloud**: Does the test feedback make sense? Are gaps clearly identified?
- **Success**: AI reports on test coverage gaps with specific examples

### Step 7 (Checkpoint)

- **Goal**: Identify security issues before they reach production
- **Do**: Read the security scan results and OWASP Top 10 review
- **Think aloud**: Is the security review thorough? Are issues explained clearly?
- **Success**: AI lists each OWASP Top 10 category and any vulnerabilities with remediation steps

### Step 8

- **Goal**: Ensure UI changes meet accessibility and design standards
- **Do**: Review UI/UX feedback (if applicable)
- **Think aloud**: Is the accessibility feedback actionable?
- **Success**: AI provides feedback on component quality and accessibility

### Step 9

- **Goal**: Identify cleanup opportunities
- **Do**: Check the list of dead code and redundancies
- **Think aloud**: Are the suggestions for cleanup reasonable? Easy to understand?
- **Success**: AI lists files to delete or consolidate with reasoning

### Step 10

- **Goal**: Ensure code is properly documented
- **Do**: Review documentation feedback and commit message validation
- **Think aloud**: Is the documentation feedback balanced (not too strict, not too lax)?
- **Success**: AI validates commit messages and identifies documentation issues

### Step 11

- **Goal**: Get prioritized, specific improvement recommendations
- **Do**: Read the compiled feedback organized by severity
- **Think aloud**: Is the feedback well-organized? Easy to prioritize?
- **Success**: AI presents structured output with critical issues, improvements, suggestions, and compliments

### Step 12

- **Goal**: Use feedback to improve code before merging
- **Do**: Review feedback and ask clarifying questions if needed
- **Think aloud**: Do you have clear next steps? Any confusion about what to do?
- **Success**: You understand all feedback and have clear next steps

## Post-test

- Stop recording
- **What was confusing?** (Note any steps where you hesitated or needed to guess)
- **What worked well?** (Note any delightful or particularly clear interactions)
- **Would you complete this in real life?** (Would you use this for actual code reviews?)

---

## Need Professional User Testing?

**Parallel Drive User Tests (6 Included)**

- Two batches of 3 tests for effective iteration
- Complete video recordings of user test sessions
- Watch users navigate your app with running commentary
- Pre-triaged AI summary of all encountered issues included

Purchase 6 user tests: https://buy.stripe.com/9B6fZ53M11jm6CqeCRcwg0a
